import asyncio
import os
import logging
from datetime import datetime
from typing import List, Optional, Dict, Any

from fastapi import APIRouter, HTTPException, Body, UploadFile, File, status

from models.schemas import (
    SearchRequest, 
    EmbeddingRequest, 
    EmbeddingResponse, 
    EmbeddingData, 
    EmbeddingUsage
)
from services.embedding_service import (
    StructuredDatasetSpec,
    StructuredEmbeddingService,
    ITSD_DATASET_SPEC,
    get_structured_embedding_service,
)
from services.job_status_service import JobStatusStore

logger = logging.getLogger(__name__)

router = APIRouter(
    prefix="/api/v1", 
    tags=["ğŸ” Vector Search"],
    responses={
        200: {"description": "ê²€ìƒ‰ ì„±ê³µ"},
        400: {"description": "ì˜ëª»ëœ ìš”ì²­"},
        500: {"description": "ì„œë²„ ì˜¤ë¥˜"}
    }
)


DATASET_SPECS: Dict[str, StructuredDatasetSpec] = {
    "itsd": ITSD_DATASET_SPEC,
}


def _resolve_dataset(dataset_name: str) -> StructuredDatasetSpec:
    spec = DATASET_SPECS.get(dataset_name.lower())
    if spec is None:
        raise HTTPException(status_code=404, detail=f"Unknown dataset: {dataset_name}")
    return spec


def _resolve_embedding_service(dataset_name: str) -> StructuredEmbeddingService:
    spec = _resolve_dataset(dataset_name)
    return get_structured_embedding_service(spec)


@router.post(
    "/datasets/{dataset_name}/embed-excel",
    summary="Upload structured dataset Excel for embedding",
    tags=["ğŸ” Vector Search"],
)
async def embed_dataset_from_excel(
    dataset_name: str,
    file: UploadFile = File(..., description="Structured dataset Excel (.xlsx)"),
):
    if not file.filename.lower().endswith(".xlsx"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Excel(.xlsx) íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        )

    service = _resolve_embedding_service(dataset_name)
    content = await file.read()
    try:
        count = await asyncio.to_thread(service.embed_from_excel_bytes, content)
        return {
            "message": f"{dataset_name} ë°ì´í„°ì…‹ ì„ë² ë”©ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "embedded_count": count,
        }
    except ValueError as exc:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail=str(exc)) from exc
    except Exception as exc:
        failed_dir = os.path.join("output", "failed_uploads", dataset_name.lower())
        os.makedirs(failed_dir, exist_ok=True)
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        failed_path = os.path.join(failed_dir, f"{timestamp}_{file.filename}")
        try:
            with open(failed_path, "wb") as handle:
                handle.write(content)
        except Exception as write_exc:
            logger.error("Failed to persist failed upload: %s", write_exc)
        logger.error(
            "Dataset embedding failed (dataset=%s, file=%s): %s",
            dataset_name,
            file.filename,
            exc,
        )
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"íŒŒì¼ ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. (ì˜¤ë¥˜ íŒŒì¼: {failed_path}) ì›ì¸: {exc}",
        )


@router.post(
    "/datasets/{dataset_name}/embed-excel-async",
    summary="Queue structured dataset embedding (async)",
    tags=["ğŸ” Vector Search"],
)
async def embed_dataset_async(
    dataset_name: str,
    file: UploadFile = File(..., description="Structured dataset Excel (.xlsx)"),
):
    if not file.filename.lower().endswith(".xlsx"):
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail="Excel(.xlsx) íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        )

    service = _resolve_embedding_service(dataset_name)
    job_store = JobStatusStore()
    job = job_store.create_job(task=f"{dataset_name}_embed", filename=file.filename)

    uploads_dir = os.path.join("output", "uploads", dataset_name.lower())
    os.makedirs(uploads_dir, exist_ok=True)
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    saved_path = os.path.join(uploads_dir, f"{job['job_id']}_{timestamp}_{file.filename}")

    content = await file.read()
    try:
        with open(saved_path, "wb") as handle:
            handle.write(content)
    except Exception as exc:
        job_store.fail_job(job["job_id"], error=f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {exc}")
        raise HTTPException(status_code=500, detail=f"ì—…ë¡œë“œ íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {exc}")

    async def _process(job_id: str, path: str) -> None:
        try:
            job_store.start_job(job_id)

            def _progress(progress: float | int, stage: Optional[str] = None) -> None:
                try:
                    JobStatusStore().set_progress(job_id, progress, stage)
                except Exception:
                    pass

            with open(path, "rb") as handle:
                payload = handle.read()
            _progress(5, "file_loaded")
            count = await asyncio.to_thread(
                service.embed_from_excel_bytes,
                payload,
                _progress,
            )
            job_store.complete_job(job_id, result={"embedded_count": int(count) if count is not None else 0})
        except Exception as exc:
            logger.error("Async dataset embedding failed (dataset=%s, job=%s): %s", dataset_name, job_id, exc)
            job_store.fail_job(job_id, error=str(exc))
        finally:
            try:
                os.remove(path)
            except Exception:
                pass

    asyncio.create_task(_process(job["job_id"], saved_path))
    return {"job_id": job["job_id"], "status": "queued"}


@router.get(
    "/datasets/{dataset_name}/embed-jobs/{job_id}",
    summary="Retrieve dataset embedding job status",
    tags=["ğŸ” Vector Search"],
)
async def get_embed_job_status(dataset_name: str, job_id: str):
    job_store = JobStatusStore()
    data = job_store.get_job(job_id)
    if not data:
        raise HTTPException(status_code=404, detail="í•´ë‹¹ job_idë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    return data


@router.post(
    "/datasets/{dataset_name}/embed-local",
    summary="Embed dataset from local default Excel",
    tags=["ğŸ” Vector Search"],
)
async def embed_dataset_from_local_file(dataset_name: str):
    spec = _resolve_dataset(dataset_name)
    if not spec.default_local_path:
        raise HTTPException(status_code=400, detail="ë¡œì»¬ ì„ë² ë”©ì´ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

    path = spec.default_local_path
    if not os.path.exists(path):
        raise HTTPException(status_code=404, detail=f"'{path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    service = _resolve_embedding_service(dataset_name)
    try:
        with open(path, "rb") as handle:
            content = handle.read()
        count = await asyncio.to_thread(service.embed_from_excel_bytes, content)
        return {
            "message": f"'{path}' íŒŒì¼ì˜ ì„ë² ë”©ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.",
            "embedded_count": count,
        }
    except Exception as exc:
        logger.error("Local dataset embedding failed (dataset=%s, path=%s): %s", dataset_name, path, exc)
        raise HTTPException(status_code=500, detail=f"ë¡œì»¬ íŒŒì¼ ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {exc}")


@router.get(
    "/datasets/{dataset_name}/index-stats",
    summary="Retrieve dataset index statistics",
    tags=["ğŸ” Vector Search"],
)
async def dataset_index_stats(dataset_name: str):
    service = _resolve_embedding_service(dataset_name)
    try:
        return service.get_index_stats()
    except Exception as exc:
        logger.error("Failed to get dataset index stats (dataset=%s): %s", dataset_name, exc)
        raise HTTPException(status_code=500, detail=str(exc))


@router.get(
    "/datasets/{dataset_name}/sample",
    summary="Sample documents for a dataset variant",
    tags=["ğŸ” Vector Search"],
)
async def dataset_sample(
    dataset_name: str,
    variant: str = "title",
    limit: int = 3,
):
    spec = _resolve_dataset(dataset_name)
    variant = (variant or "").strip().lower()
    allowed_variants = {
        spec.title_variant_name,
        spec.content_variant_name,
        spec.combined_variant_name,
    }
    if variant not in allowed_variants:
        raise HTTPException(
            status_code=400,
            detail=f"variant must be one of: {', '.join(sorted(allowed_variants))}",
        )
    service = _resolve_embedding_service(dataset_name)
    safe_limit = max(1, min(50, int(limit)))
    try:
        return service.sample_documents(variant, limit=safe_limit)
    except Exception as exc:
        logger.error("Failed to sample dataset documents (dataset=%s, variant=%s): %s", dataset_name, variant, exc)
        raise HTTPException(status_code=500, detail=str(exc))


@router.post(
    "/search", 
    response_model=List[dict],
    summary="ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰",
    description="""
    **ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ìœ ì‚¬í•œ ë¬¸ì„œë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤.**
    
    ### ğŸ” ê²€ìƒ‰ ê¸°ëŠ¥
    - **ì˜ë¯¸ì  ê²€ìƒ‰**: í…ìŠ¤íŠ¸ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ì—¬ ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
    - **ë©”íƒ€ë°ì´í„° í•„í„°ë§**: íŒŒì¼ íƒ€ì…, ì–¸ì–´, íƒœê·¸ ë“±ìœ¼ë¡œ ê²°ê³¼ í•„í„°ë§
    - **ë¶„ì„ ê²°ê³¼ë³„ ê²€ìƒ‰**: analysis_idë¡œ íŠ¹ì • ë¶„ì„ ê²°ê³¼ë§Œ ê²€ìƒ‰
    - **ìµœì‹  commit ìš°ì„  ê²€ìƒ‰**: repository_urlë¡œ ìµœì‹  commit ë¶„ì„ ê²°ê³¼ ìš°ì„  ê²€ìƒ‰ â­ **NEW**
    - **ê·¸ë£¹ëª…ìœ¼ë¡œ ê²€ìƒ‰**: group_nameìœ¼ë¡œ íŠ¹ì • ê·¸ë£¹ì— ì†í•œ ë ˆí¬ì§€í† ë¦¬ ë¶„ì„ ê²°ê³¼ ê²€ìƒ‰ â­ **NEW**
    - **ìœ ì‚¬ë„ ì ìˆ˜**: ê° ê²°ê³¼ì˜ ê´€ë ¨ì„± ì ìˆ˜ ì œê³µ
    
    ### ğŸ“ ì‚¬ìš© ì˜ˆì‹œ
    ```bash
    # ì¼ë°˜ ê²€ìƒ‰
    curl -X POST "http://localhost:8001/api/v1/search" \
      -H "Content-Type: application/json" \
      -d '{ 
        "query": "Python í•¨ìˆ˜ ì •ì˜",
        "k": 5,
        "filter_metadata": {
          "file_type": "python"
        }
      }'
    
    # íŠ¹ì • ë¶„ì„ ê²°ê³¼ì—ì„œë§Œ ê²€ìƒ‰
    curl -X POST "http://localhost:8001/api/v1/search" \
      -H "Content-Type: application/json" \
      -d '{ 
        "query": "Python í•¨ìˆ˜ ì •ì˜",
        "k": 5,
        "analysis_id": "3cbf3db0-fd9e-410c-bdaa-30cdeb9d7d6c"
      }'
    
    # íŠ¹ì • ë ˆí¬ì§€í† ë¦¬ì˜ ìµœì‹  commit ë¶„ì„ ê²°ê³¼ì—ì„œ ê²€ìƒ‰ (NEW!)
    curl -X POST "http://localhost:8001/api/v1/search" \
      -H "Content-Type: application/json" \
      -d '{ 
        "query": "Python í•¨ìˆ˜ ì •ì˜",
        "k": 5,
        "repository_url": "https://github.com/octocat/Hello-World.git"
      }

    # íŠ¹ì • ê·¸ë£¹ëª…ìœ¼ë¡œ ê²€ìƒ‰ (NEW!)
    curl -X POST "http://localhost:8001/api/v1/search" \
      -H "Content-Type: application/json" \
      -d '{ 
        "query": "ê²°ì œ ëª¨ë“ˆ",
        "k": 5,
        "group_name": "PaymentServiceTeam"
      }'
    
    ### ğŸ¯ ê²€ìƒ‰ íŒ
    - êµ¬ì²´ì ì¸ í‚¤ì›Œë“œ ì‚¬ìš© (ì˜ˆ: "FastAPI ë¼ìš°í„°" vs "ì›¹ ê°œë°œ")
    - analysis_idë¡œ íŠ¹ì • ë¶„ì„ ê²°ê³¼ë§Œ ê²€ìƒ‰í•˜ì—¬ ì •í™•ë„ í–¥ìƒ
    - group_nameìœ¼ë¡œ íŠ¹ì • ê·¸ë£¹ì— ì†í•œ ë ˆí¬ì§€í† ë¦¬ ë¶„ì„ ê²°ê³¼ë§Œ ê²€ìƒ‰ â­ **NEW** # <-- ì„¤ëª… ì¶”ê°€
    - ë©”íƒ€ë°ì´í„° í•„í„°ë¡œ ê²°ê³¼ ë²”ìœ„ ì œí•œ
    - k ê°’ ì¡°ì •ìœ¼ë¡œ ê²°ê³¼ ìˆ˜ ì¡°ì ˆ (ê¸°ë³¸ê°’: 5)
    """,
    response_description="ìœ ì‚¬í•œ ë¬¸ì„œ ëª©ë¡ê³¼ ìœ ì‚¬ë„ ì ìˆ˜"
)
async def search_embeddings(request: SearchRequest = Body(...)):
    """ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ - ì˜ë¯¸ì  ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œë¥¼ ì°¾ìŠµë‹ˆë‹¤."""
    try:
        from services.embedding_service import get_embedding_service
        from config.settings import settings
        
        query = request.query
        k = request.k
        filter_metadata = request.filter_metadata
        analysis_id = request.analysis_id
        repository_url = request.repository_url
        group_name = request.group_name

        # analysis_idê°€ ì œê³µëœ ê²½ìš° í•„í„°ì— ì¶”ê°€
        if analysis_id:
            if filter_metadata is None:
                filter_metadata = {}
            filter_metadata["analysis_id"] = analysis_id
            logger.info(f"Searching with analysis_id filter: {analysis_id}")
        
        # group_nameì´ ì œê³µëœ ê²½ìš° í•„í„°ì— ì¶”ê°€
        if group_name:
            if filter_metadata is None:
                filter_metadata = {}
            filter_metadata["group_name"] = group_name
            logger.info(f"Searching with group_name filter: {group_name}")

        embedding_service = get_embedding_service()
        results = embedding_service.search_similar_documents(
            query, 
            k=k, 
            filter_metadata=filter_metadata, 
            repository_url=repository_url  # ìµœì‹  commit ë¶„ì„ ê²°ê³¼ ìš°ì„  ê²€ìƒ‰
        )
        return results
    except Exception as e:
        logger.error(f"Failed to search embeddings: {e}")
        raise HTTPException(status_code=500, detail=f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")


@router.get(
    "/stats", 
    response_model=dict,
    summary="ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µê³„",
    description="""
    **ChromaDB ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ì˜ í†µê³„ ì •ë³´ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.**
    
    ### ğŸ“Š ì œê³µ ì •ë³´
    - **ì´ ë¬¸ì„œ ìˆ˜**: ì €ì¥ëœ ë¬¸ì„œì˜ ê°œìˆ˜
    - **ë²¡í„° ì°¨ì›**: ì„ë² ë”© ë²¡í„°ì˜ ì°¨ì› ìˆ˜
    - **ì»¬ë ‰ì…˜ ì •ë³´**: ë°ì´í„°ë² ì´ìŠ¤ ì»¬ë ‰ì…˜ ìƒíƒœ
    - **ì¸ë±ìŠ¤ ìƒíƒœ**: ê²€ìƒ‰ ì¸ë±ìŠ¤ ì •ë³´
    
    ### ğŸ“ ì‚¬ìš© ì˜ˆì‹œ
    ```bash
    curl -X GET "http://localhost:8001/api/v1/stats"
    ```
    
    ### ğŸ’¡ í™œìš© ë°©ë²•
    - ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ëª¨ë‹ˆí„°ë§
    - ê²€ìƒ‰ ì„±ëŠ¥ ìµœì í™” ì°¸ê³ 
    - ì €ì¥ ìš©ëŸ‰ ê´€ë¦¬
    """,
    response_description="ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´"
)
async def get_embedding_stats():
    """ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì¡°íšŒ - ChromaDBì˜ ìƒíƒœì™€ í†µê³„ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
    try:
        from services.embedding_service import get_embedding_service
        from config.settings import settings
        
        embedding_service = get_embedding_service()
        stats = embedding_service.get_collection_stats()
        return stats
    except Exception as e:
        logger.error(f"Failed to get embedding stats: {e}")
        raise HTTPException(status_code=500, detail=f"í†µê³„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.post(
    "/embed_rdb_schema",
    response_model=Dict[str, Any],
    summary="RDB ìŠ¤í‚¤ë§ˆ ì„ë² ë”©",
    description="""
    **MariaDB ë°ì´í„°ë² ì´ìŠ¤ì˜ ìŠ¤í‚¤ë§ˆ(í…Œì´ë¸”, ì»¬ëŸ¼) ì •ë³´ë¥¼ ì¶”ì¶œí•˜ì—¬ ì„ë² ë”©í•˜ê³  ChromaDBì— ì €ì¥í•©ë‹ˆë‹¤.**
    
    ì´ ì‘ì—…ì„ í†µí•´ RDBì˜ êµ¬ì¡°ë¥¼ ìì—°ì–´ ì¿¼ë¦¬ë¡œ ê²€ìƒ‰í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.
    """,
    response_description="ì„ë² ë”© ì‘ì—… ê²°ê³¼"
)
async def embed_rdb_schema():
    """RDB ìŠ¤í‚¤ë§ˆë¥¼ ì„ë² ë”©í•˜ì—¬ ë²¡í„° ì €ì¥ì†Œì— ì¶”ê°€í•©ë‹ˆë‹¤."""
    try:
        from services.rdb_embedding_service import RDBEmbeddingService
        rdb_embedding_service = RDBEmbeddingService()
        result = rdb_embedding_service.extract_and_embed_schema()
        if result["status"] == "error":
            raise HTTPException(status_code=500, detail=result["message"])
        return result
    except Exception as e:
        logger.error(f"Failed to embed RDB schema: {e}")
        raise HTTPException(status_code=500, detail=f"RDB ìŠ¤í‚¤ë§ˆ ì„ë² ë”© ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.post("/embeddings", response_model=EmbeddingResponse, summary="í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± (OpenAI í˜¸í™˜)")
async def create_text_embeddings(request: EmbeddingRequest):
    """
    OpenAI í˜¸í™˜ í˜•ì‹ìœ¼ë¡œ í…ìŠ¤íŠ¸ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    try:
        from services.embedding_service import get_embedding_service
        if isinstance(request.input, str):
            texts = [request.input]
        else:
            texts = request.input

        embedding_service = get_embedding_service()
        
        # Use the new create_embeddings method
        embeddings_vectors = embedding_service.create_embeddings(texts)
        
        embedding_data = []
        total_tokens = 0

        for i, embedding_vector in enumerate(embeddings_vectors):
            embedding_data.append(EmbeddingData(embedding=embedding_vector, index=i))
            total_tokens += len(texts[i].split()) # Simple token estimation

        return EmbeddingResponse(
            data=embedding_data,
            model=request.model,
            usage=EmbeddingUsage(prompt_tokens=total_tokens, total_tokens=total_tokens)
        )
    except Exception as e:
        logger.error(f"Failed to create text embeddings: {e}")
        raise HTTPException(status_code=500, detail=f"í…ìŠ¤íŠ¸ ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")

@router.get("/groups", response_model=List[str], summary="ë“±ë¡ëœ ëª¨ë“  ê·¸ë£¹ ì´ë¦„ ì¡°íšŒ")
async def get_all_group_names():
    """
    ChromaDBì— ì €ì¥ëœ ëª¨ë“  ë¬¸ì„œì—ì„œ ìœ ë‹ˆí¬í•œ `group_name` ëª©ë¡ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    try:
        from services.embedding_service import get_embedding_service
        embedding_service = get_embedding_service()
        group_names = embedding_service.get_all_group_names()
        return group_names
    except Exception as e:
        logger.error(f"Failed to get all group names: {e}")
        raise HTTPException(status_code=500, detail=f"ê·¸ë£¹ ì´ë¦„ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}")
